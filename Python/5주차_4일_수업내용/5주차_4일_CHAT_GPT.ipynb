{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6GFO0VM4ejC",
        "outputId": "c9506cfa-682f-4a32-d89d-39d322652d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.9.0 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI  # OpenAI 모듈 불러오기\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "client = OpenAI(api_key='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')  # 사용자의 API 키로 대체해야 함\n",
        "\n",
        "# ChatGPT를 사용한 텍스트 생성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Hello World!\"}]\n",
        ")\n",
        "# API 응답에서 마지막 메시지의 내용을 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezkFSQFmC6_C",
        "outputId": "2d14b475-dc5b-491c-9be4-2bc51b00d492"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# ChatGPT를 사용한 텍스트 생성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Translate the following English text to French: 'Hello, how are you?'\"}]\n",
        ")\n",
        "\n",
        "#응답 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgeg9lC2ELlZ",
        "outputId": "89d9a707-9a0a-4db4-8433-1df38f70d1ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour, comment ça va ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# ChatGPT를 사용한 텍스트 생성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Translate the following English text to korea: 'Hello, how are you?'\"}]\n",
        ")\n",
        "\n",
        "#응답 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5tApMSePuO7",
        "outputId": "df4716a2-80d9-4bd4-ce64-b11abe6cfd0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요, 어떻게 지내세요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = [{\"role\" : \"user\", \"content\" : \"Translate the following korean text to English: 안녕하세요 오늘 날씨가 좋네요. 햇살이 맑아요\"}],\n",
        "        max_tokens=10,\n",
        "        temperature=0.7,\n",
        "        top_p=0.8,\n",
        "        frequency_penalty=0.2\n",
        "    )\n",
        "    print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "555mohS4Pyy6",
        "outputId": "19d2904d-f2e5-4663-d98a-d8f9712d45d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, today's weather is nice. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, today the weather is nice. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, today's weather is good. The sunlight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_chatbot(messages):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\", messages = messages\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "prompt_role = \"너는 블로그 전문가, 파워블로그처럼 글을 써야해.\\\n",
        "                개발자의 직업관에 대한 글을 써야하고,\\\n",
        "                그리고 취업을 준비하는 20대 독자들에게 잘 보일수 있도록 글을 써야되\\\n",
        "                SEO최적화된 글을 써야되\""
      ],
      "metadata": {
        "id": "0ogX_ORcQQfD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "def assist_blogger(\n",
        "    facts: List[str], tone: str, length_words: int, style: str\n",
        "):\n",
        "    facts = \", \".join(facts)\n",
        "    prompt_role = \"너는 블로그 전문가고, 파워블로그처럼 글을 써야해\"\n",
        "    prompt = f\"{prompt_role} \\\n",
        "            FACTS: {facts} \\\n",
        "            TONE: {tone} \\\n",
        "            LEGNTH: {length_words} words \\\n",
        "            STYLE: {style}\"\n",
        "    return ask_chatbot([{\"role\": \"user\", \"content\": prompt}])"
      ],
      "metadata": {
        "id": "TC7hcjMtQuCD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    assist_blogger(\n",
        "        [\"대학 진학 이후의 개발자의 삶은?\"], \"informal\", 100, \"blogpost\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6uTW3nAQwPk",
        "outputId": "a79f8212-3881-4ff9-a582-b33104ac7cab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요, 여러분! 오늘은 대학 진학 이후의 개발자의 삶에 대해 이야기해보려고 합니다. 개발자라는 직업은 많은 사람들에게 매력적으로 다가오지만, 대학을 졸업하고 현실 세계에서 개발자로서의 삶을 시작하는 것은 쉽지 않은 일이죠.\n",
            "\n",
            "먼저, 대학을 졸업한 후 개발자로서의 삶은 무척 바쁩니다. 업무에 빠져들어 코드를 작성하고 버그를 고치는 일에 한 가지로 힘을 쏟아야 하기 때문이죠. 그래도 개발자로 성공하기 위해서는 밤낮없이 노력해야 한다는 것을 잊지 마세요!\n",
            "\n",
            "또한, 대학 진학 이후 개발자의 삶은 계속해서 새로운 기술을 익히고 학습해야 한다는 점도 기억해야 합니다. IT 업계는 계속해서 변화하고 발전하기 때문에, 앞서 배운 지식만으로는 따라가기 어렵습니다. 따라서, 새로운 프로그래밍 언어나 도구를 배우는 공부를 꾸준히 해야 합니다.\n",
            "\n",
            "또한, 개발자로서의 성장을 위해 개인 프로젝트를 진행하는 것도 중요합니다. 대학에서는 팀 프로젝트나 과제가 주를 이루었지만, 실무에서는 개인 프로젝트를 통해 자신의 능력을 향상시킬 수 있습니다. 새로운 아이디어를 구상하고 스스로 문제를 해결하는 과정은 개발자로 성장하는데 큰 도움이 될 것입니다.\n",
            "\n",
            "마지막으로, 대학 진학 이후의 개발자의 삶은 팀워크의 중요성을 다시 한 번 느끼게 됩니다. 프로젝트에서 여러 사람과 함께 일하면서 의사소통과 협업의 중요성을 지속적으로 경험하게 됩니다. 따라서, 개발자로서의 성장을 위해서는 팀워크 능력을 함양하는 것이 필수적이라고 할 수 있습니다.\n",
            "\n",
            "대학 진학 이후 개발자로서의 삶은 정말 바쁘고 힘들지만, 동시에 매우 보람찬 일입니다. 새로운 기술을 배우고 성장하며, 팀과 함께 협업하며 멋진 프로젝트를 완성하는 과정은 개발자로서의 진정한 삶이기 때문입니다. 따라서, 어려움을 극복하고 유연하게 변화에 적응하며 개발자로서의 삶을 즐길 준비를 하면 좋을 것 같습니다.\n",
            "\n",
            "이상으로 대학 진학 이후의 개발자의 삶에 대해 이야기해봤는데요. 여러분들은 어떻게 생각하시나요? 개발자로서의 경험을 공유하고 싶은 이야기가 있다면 언제든지 남기세요! 함께 이야기 나누는 것도 개발자로 성장하는데 큰 도움이 될 거예요. 감사합니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    assist_blogger(\n",
        "        facts =[\"Chat GPT 등장이후의 취업 전략은?\"],\n",
        "        tone = \"정중하게\",\n",
        "        length_words = 200,\n",
        "        style= \"파워블로그 스럽게\"\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSsJGxyuRGWz",
        "outputId": "a278405c-93fa-4644-90b9-caa5848bc5a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요. 저는 블로그 전문가로서 파워블로그 스럽게 글을 써드리겠습니다. 오늘은 Chat GPT 등장 이후의 취업 전략에 대해 이야기해보겠습니다.\n",
            "\n",
            "Chat GPT 등의 대화형 AI 모델이 등장한 이후로, 취업 전략도 변화하고 있습니다. 기존에는 이력서와 자기 소개서를 작성하고 면접 실력을 강화하는 것이 중요한 포인트였지만, 이제는 대화형 AI와의 경험이 중요한 요소로 떠오르고 있습니다.\n",
            "\n",
            "AI 모델과의 대화 경험은 기업에 대한 이해도를 넓히고 문제 해결력을 증진시키는 데 도움이 됩니다. 경험을 바탕으로 한 적극적인 대응과 논리적인 의사소통은 면접에서 큰 장점으로 작용할 수 있습니다.\n",
            "\n",
            "따라서 취업 전략의 일환으로, 대화형 AI와의 상호작용 경험을 적극적으로 쌓아나가야 합니다. AI와의 대화 훈련 방법은 다양한데, 본인의 관심 분야에 관련된 AI 모델을 활용하거나, AI와의 대화를 시뮬레이션한 훈련 프로그램을 활용하는 방법 등이 있습니다.\n",
            "\n",
            "또한, AI 기술을 활용한 프로젝트나 경험을 포트폴리오에 직접적으로 담는 것도 중요합니다. 새로운 기술과 도전적인 프로젝트를 통해 AI 관련 업무에 대한 이해도와 역량을 강화할 수 있습니다.\n",
            "\n",
            "이 외에도 기존의 취업 전략인 커뮤니케이션 능력, 문제 해결력, 리더십 등은 여전히 중요한 요소입니다. 그러나 Chat GPT 등의 등장으로 AI와의 상호작용 경험과 이해도가 더욱 강조되고 있으므로, 이를 적극적으로 발전시키는 것이 취업 전략에 큰 도움이 될 것입니다.\n",
            "\n",
            "요약하자면, Chat GPT 등장 이후의 취업 전략은 AI와의 대화 경험을 쌓고 이를 포트폴리오에 담는 것이 중요합니다. AI 기술에 대한 이해도와 역량은 취업시장에서 더욱 귀중히 여겨지고 있으므로, 이를 잘 반영하여 준비하는 것이 필요합니다. 채용 과정에서 AI와의 대화 경험이 면접에서 큰 장점으로 작용할 수 있으니, 주어진 기회를 통해 목표를 달성할 수 있기를 바랍니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첨부된 파일을 읽고 작은 부분으로 나누기 위한 코드입니다.\n",
        "\n",
        "# 파일 경로 설정\n",
        "file_path = '/content/English_But_what_is_a_neural_network____Chapter_1_Deep_learning_DownSub.com.txt'\n",
        "\n",
        "# 파일을 읽어서 내용을 저장\n",
        "with open(file_path, 'r') as file:\n",
        "    transcript = file.read()\n",
        "\n",
        "# 텍스트를 나눌 최대 길이 설정 (토큰 수가 아닌 문자 수 기준)\n",
        "max_length = 5000  # 각 부분의 최대 길이 (문자 수)\n",
        "\n",
        "# 텍스트를 작은 부분으로 나누는 함수\n",
        "def split_into_parts(text, length):\n",
        "    return [text[i:i+length] for i in range(0, len(text), length)]\n",
        "\n",
        "# 텍스트를 여러 부분으로 나눔\n",
        "parts = split_into_parts(transcript, max_length)\n",
        "\n",
        "# 나누어진 부분들의 수와 첫 부분의 내용 일부를 출력\n",
        "num_parts = len(parts)\n",
        "first_part_preview = parts[0][:500]  # 첫 부분의 처음 500자\n",
        "\n",
        "num_parts, first_part_preview"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syyBpLrBTPuy",
        "outputId": "da53af8b-9445-4849-ec9f-c7c2d8c6b724"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " \"This is a 3. It's sloppily written and rendered at an extremely low resolution of 28x28 pixels,\\n\\nbut your brain has no trouble recognizing it as a 3. And I want you to take a moment\\n\\nto appreciate how crazy it is that brains can do this so effortlessly. I mean, this,\\n\\nthis and this are also recognizable as 3s, even though the specific values of each pixel\\n\\nis very different from one image to the next. The particular light-sensitive cells in your\\n\\neye that are firing when you see this 3 are very \")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 부분만 사용\n",
        "first_part = parts[0]\n",
        "\n",
        "# 첫 번째 부분에 대한 번역 요청\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages = [\n",
        "        {\"role\" : \"system\", \"content\" : \"너는 유튜브를 영어에서 한국어로 번역하는 번역가이자, 요약을 잘하는 역할을 할꺼야\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"업로드한 파일을 한국어로 변역해줘\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"한국어로 번역한 내용을 요약해\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : first_part}\n",
        "      ],\n",
        ")\n",
        "\n",
        "# 번역 결과 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEspK5AhUf-b",
        "outputId": "e4b1680c-3b6b-4e21-f6ce-2a1a58ab6b77"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 영상에서는 손글씨 숫자를 인식하는 능력을 갖춘 인공신경망을 만들어볼 것입니다. 이것은 주제를 소개하는데에 널리 사용되는 예시입니다. 이 영상과 다음 영상에서는 인공신경망이 어떻게 학습하는지에 대해 자세히 알아볼 예정입니다. 인공신경망은 뇌에서 영감을 받았으며, 각 뉴런들은 숫자를 저장하는 기능을 가지고 있습니다. 각 뉴런은 0에서 1 사이의 숫자를 저장하며, 픽셀에 해당하는 그레이스케일 값입니다. 첫 번째 층은 784개의 뉴런으로 구성되어 있고, 입력 이미지의 픽셀 각각에 해당하는 뉴런들입니다. 마지막 층은 10개의 뉴런으로 구성되어 있으며, 각 숫자에 해당하는 뉴런입니다. 중간에는 가리키지 않는 층들이 있고, 우리는 그것들이 숫자 인식 과정에 어떻게 기여하는지 이해하기 위해 이를 좀 더 알아볼 것입니다. 이 네트워크는 이미 숫자를 인식하는 능력을 갖추기 위해 학습된 상태이며, 그에 대한 예시를 보여줄 것입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XGv_yvRzU73B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}